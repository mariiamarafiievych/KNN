{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3fPKMUGvoSnw"
   },
   "source": [
    "# K-Nearest neighbours\n",
    "\n",
    "Welcome to your next lab! You will build a k-nearest neighbours classifier.\n",
    "\n",
    "You will implement this model in OOP way.\n",
    "\n",
    "**You will learn to:**\n",
    "- Build the general architecture of a learning algorithm with OOP in mind:\n",
    "    - Helper functions\n",
    "        - Calculating euclidian distance\n",
    "        - Finding labels of k-nearest neighbours\n",
    "    - Main Model Class\n",
    "        - Training\n",
    "        - Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kB8G-M2MDvLc"
   },
   "source": [
    "## 1 - Packages ##\n",
    "\n",
    "First, let's run the cell below to import all the packages that you will need during this assignment. \n",
    "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a famous library to plot graphs in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "4YWD8gOQoSn1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WgdtGMZoSn3"
   },
   "source": [
    "## 2 - Overview of the Dataset  ##\n",
    "\n",
    "**Problem Statement**: You are given a dataset  containing:\n",
    "    - a training set of m_train examples\n",
    "    - a test set of m_test examples\n",
    "    - each example is of shape (number of features, 1)\n",
    "    \n",
    "    \n",
    "Iris Plants Database\n",
    "===========================\n",
    "\n",
    "Notes\n",
    "------\n",
    "Data Set Characteristics:  \n",
    "\n",
    "    :Number of Instances: 150 (50 in each of three classes)\n",
    "\n",
    "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
    "    \n",
    "    :Attribute Information:\n",
    "        - sepal length in cm\n",
    "        - sepal width in cm\n",
    "        - petal length in cm\n",
    "        - petal width in cm\n",
    "        - class:\n",
    "            - Iris-Setosa\n",
    "            - Iris-Versicolour\n",
    "            - Iris-Virginica\n",
    "        \n",
    "    :Missing Attribute Values: None   \n",
    "    \n",
    "    :Class Distribution: 33.3% for each of 3 classes.\n",
    "    \n",
    "    :Missing Attribute Values: None\n",
    "\n",
    "    :Creator: R.A. Fisher\n",
    "    \n",
    "    :Donor: Michael Marshall\n",
    "\n",
    "This is a copy of UCI ML iris datasets.http://archive.ics.uci.edu/ml/datasets/Iris\\ \n",
    "\n",
    "The famous Iris database, first used by Sir R.A Fisher.\n",
    "This is perhaps the best known database to be found in the pattern recognition literature.  Fisher's paper is a classic in the field and is referenced frequently to this day.  (See Duda & Hart, for example.)  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.\n",
    "     \n",
    "**References**\n",
    "\n",
    "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\" Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to Mathematical Statistics\" (John Wiley, NY, 1950).\n",
    "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.(Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.  \n",
    "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System Structure and Classification Rule for Recognition in Partially Exposed Environments\".  IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
    "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\". IEEE Transactions on Information Theory, May 1972, 431-433.\n",
    "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II conceptual clustering system finds 3 classes in the data.\n",
    "   - many more! (see https://archive.ics.uci.edu/ml/datasets/iris)',\n",
    "\n",
    "\n",
    "You will build a simple algorithm that can correctly classify training examples depending on your particular dataset.\n",
    "\n",
    "<b>Let's get more familiar with the dataset. Load the data by running the following code.<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "XFcMycDXoSn3"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import datasets\n",
    "    \n",
    "    iris = datasets.load_iris()\n",
    "    \n",
    "    train_set_x, test_set_x, train_set_y, test_set_y = train_test_split(iris.data, iris.target, test_size=0.33, random_state=42)\n",
    "    \n",
    "    return train_set_x, test_set_x, train_set_y, test_set_y, iris\n",
    "\n",
    "train_set_x, test_set_x, train_set_y, test_set_y, visualization_set = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T3W81DRfoSn6"
   },
   "source": [
    "Many software bugs in machine learning come from having matrix/vector dimensions that don't fit. If you can keep your matrix/vector dimensions straight you will go a long way toward eliminating many bugs. \n",
    "\n",
    "**Exercise:** Find the values for:\n",
    "    - m_train (number of training examples)\n",
    "    - m_test (number of test examples)\n",
    "    \n",
    "Remember that `train_set_x` is a numpy-array of shape (number of examples, number of features). For instance, you can access `m_train` by writing `train_set_x.shape[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "Tg5YOrDooSn6"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (â‰ˆ 2 lines of code)\n",
    "m_train = \n",
    "m_test = \n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "\n",
    "print (\"train_set_x shape: \" + str(train_set_x.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UScGW9o7oSn9"
   },
   "source": [
    "**Expected Output for m_train, m_test**: \n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "      <td><b>m_train</b></td>\n",
    "    <td> 100 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td><b>m_test</b></td>\n",
    "    <td> 50 </td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJkv5yeLoSn9"
   },
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XzvXXFZkoSn-"
   },
   "source": [
    "Let's print a histogram of the quantity to predict: class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "QHk6VAE8oSn_"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(visualization_set.target)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q34hprotoSoA"
   },
   "source": [
    "And it is very useful to understand the join distribution for each feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "LwEWS5RYoSoB"
   },
   "outputs": [],
   "source": [
    "for index, feature_name in enumerate(visualization_set.feature_names):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.scatter(visualization_set.data[:, index], visualization_set.target)\n",
    "    plt.ylabel(\"Class\", size=15)\n",
    "    plt.xlabel(feature_name, size=15)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6v8Z_PfoSoE"
   },
   "source": [
    "<font color='green'>\n",
    "    <b>What you need to remember:</b>\n",
    "\n",
    "Common steps for pre-processing a new dataset are:\n",
    "- Figure out the dimensions and shapes of the problem (m_train, m_test, ...)\n",
    "- Reshape the datasets such that each example is now a vector of size (n, 1)\n",
    "- \"Standardize\" the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AVXotD0AoSoF"
   },
   "source": [
    "## 3 - General Architecture of the learning algorithm ##\n",
    "\n",
    "The K-nearest neighbours algorithm essentially boils down to forming a majority vote between the K most similar instances to a given \"unseen\" observation. \n",
    "\n",
    "**Mathematical expression of the algorithm**:\n",
    "\n",
    "Similarity is defined according to a distance metric between two data points. Let's use the Euclidean distance given by\n",
    "\n",
    "\n",
    "$$d(x, {x}') = \\sqrt{(x_{1} - {x}'_{1})^2 + ... + (x_{n} - {x}'_{n})^2} \\tag{1}$$\n",
    "\n",
    "More formally, given a positive integer K, an unseen observation x and a similarity metric d, KNN classifier performs the following two steps:\n",
    "\n",
    "   - It runs through the whole dataset computing distance $d$ between each unseen point $x$ and each training observation. We'll take the K points in the training data that are closest to $x$ in the set of unseen points $\\mathcal{A}$. \n",
    "\n",
    "   - Then it estimates the conditional probability for each class, that is the fraction of points in $\\mathcal{A}$ with that given class label. (Note $I(x)$ is the indicator function which evaluates to 1 when the argument $x$ is true and 0 otherwise)\n",
    "   \n",
    "   $$P(y = j | X = x) = \\frac{1}{K} \\sum_{i \\in \\mathcal{A}} I(y^{(i)} = j)\\tag{2}$$\n",
    "   Finally, input x gets assigned to the class with the largest probability.\n",
    "   \n",
    "**Key steps**:\n",
    "In this exercise, you will carry out the following steps: \n",
    "    - Calculate euclidian distances\n",
    "    - Find k-nearest neighbours' labels\n",
    "    - Use the learned parameters to make predictions (on the test set)\n",
    "    - Analyse the results and conclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w52cmoSYoSoF"
   },
   "source": [
    "### 3.1 - Helper utilities###\n",
    "\n",
    "\n",
    "In this exercise, you will lear more about custom implemenation:\n",
    "\n",
    "- Calculating Euclidian Distances\n",
    "- Finding k-nearest neghbours' labesls\n",
    "\n",
    "\n",
    "Let's get more detailed look at these functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GLSL0alwoSoG"
   },
   "source": [
    "Implement calculation of the Euclidean distance in the cell below. You have to calculate distances from all unknown points to all known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "5RqfrjRioSoH"
   },
   "outputs": [],
   "source": [
    "# euclidian distance\n",
    "\n",
    "def euclidian_dist(x_known,x_unknown):\n",
    "    \"\"\"\n",
    "    This function calculates euclidian distance between each pairs of known and unknown points\n",
    "    \n",
    "    Argument:\n",
    "    x_known -- array of training data with shape (num_examples, num_features)\n",
    "    x_unknown -- array of test data with shape (num_examples, num_features)\n",
    "    \n",
    "    Returns:\n",
    "    dists -- array of euclidian distances between each pairs of known and unknown points, \n",
    "    initialized as np.array of zeros with shape of (num_pred,num_data)\n",
    "    \n",
    "    \"\"\"\n",
    "    num_pred = x_unknown.shape[0]\n",
    "    num_data = x_known.shape[0]\n",
    "    \n",
    "    \n",
    "    ### START CODE HERE ### (â‰ˆ 1 line of code)\n",
    "    dists = \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    for i in range(num_pred):\n",
    "        for j in range(num_data):\n",
    "            # calculate euclidian distance here\n",
    "            ### START CODE HERE ### (â‰ˆ 1-2 lines of code)\n",
    "            dists[i,j] = \n",
    "            ### END CODE HERE ###\n",
    "            \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "KIUqM1UPoSoJ"
   },
   "outputs": [],
   "source": [
    "x1 = np.array([[1,1], [3,3], [4, 4]])\n",
    "x2 = np.array([[2,2],[3,3], [5, 5]])\n",
    "d = euclidian_dist(x1, x2)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-cgD2zJoSoL"
   },
   "source": [
    "**Expected Output**: \n",
    "<table style=\"width:25%\">\n",
    "  <tr>\n",
    "    <td> [[1.41421356 1.41421356 2.82842712] </td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>[2.82842712 0.         1.41421356] </td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> [5.65685425 2.82842712 1.41421356]] </td> \n",
    "  </tr>\n",
    "\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qD8xm5WWoSoM"
   },
   "source": [
    "Implement function that returns labels of k-nearest neighbours to each sample for unknown data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "VscNxLABoSoN"
   },
   "outputs": [],
   "source": [
    "# k nearest labels\n",
    "\n",
    "def k_nearest_labels(dists, y_known, k):\n",
    "    \"\"\"\n",
    "    This function returns labels of k-nearest neighbours to each sample for unknown data.\n",
    "    \n",
    "    Argument:\n",
    "    dists -- array of euclidian distances between each pairs of known and unknown points\n",
    "    with shape (num_test_examples, num_train_examples)\n",
    "    y_known -- array of train data labels\n",
    "    k -- scalar, which means number of nearest neighbours\n",
    "    \n",
    "    Returns:\n",
    "    knearest_labels -- array with shape (num_samples, k) which contains labels of k nearest neighbours for each sample \n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    num_pred = dists.shape[0]\n",
    "    n_nearest = []\n",
    "    \n",
    "    for j in range(num_pred):\n",
    "        dst = dists[j]\n",
    "        \n",
    "        # count k closest points \n",
    "        ### START CODE HERE ### (â‰ˆ 1-2 lines of code)\n",
    "        closest_y = \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        n_nearest.append(closest_y)\n",
    "    return np.asarray(n_nearest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "0II_W0qsoSoO"
   },
   "outputs": [],
   "source": [
    "y = np.array([2, 3, 1])\n",
    "knl = k_nearest_labels(d, y, 2)\n",
    "print(knl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhcSOwbdoSoR"
   },
   "source": [
    "**Expected Output**:\n",
    "    \n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td>[[2 3] </td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>[3 1] </td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>[1 3]] </td> \n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8UWJSEWoSoR"
   },
   "source": [
    "### 3.2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "zqWZtW6zoSoU"
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: K-nearest Neighbours\n",
    "\n",
    "class KNearest_Neighbours(object):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    k: int\n",
    "        The number of nearest neighbours\n",
    "    \"\"\"\n",
    "    def __init__(self, k):\n",
    "        \n",
    "        self.k = k\n",
    "        self.test_set_x = None\n",
    "        self.train_set_x = None\n",
    "        self.train_set_y = None\n",
    "\n",
    "        \n",
    "    def fit(self, train_set_x, train_set_y):\n",
    "        \n",
    "        ### START CODE HERE ### \n",
    "        \n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    def predict(self, test_set_x):\n",
    "        \n",
    "        # Returns list of predicted labels for test set; type(prediction) -> list, len(prediction) = len(test_set_y)\n",
    "        ### START CODE HERE ### \n",
    "\n",
    "        \n",
    "        ### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtW3c0iGoSoV"
   },
   "source": [
    "## 4 - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VmKBX48BoSoW"
   },
   "source": [
    "First of all, we should define a number of nearest neighbours (k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "mVRGoEajoSoX"
   },
   "outputs": [],
   "source": [
    "k = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r1YBaP4RoSoY"
   },
   "source": [
    "Now we can initialize our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "h_TdFusyoSoZ"
   },
   "outputs": [],
   "source": [
    "model = KNearest_Neighbours(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "agaOZ4_goSob"
   },
   "source": [
    "Let's train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "G2epO9r-oSoc"
   },
   "outputs": [],
   "source": [
    "model.fit(train_set_x, train_set_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rHvVMX-aoSof"
   },
   "source": [
    "## 5 - Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "QMan77feoSog"
   },
   "outputs": [],
   "source": [
    "y_predictions = model.predict(test_set_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04LRBO_BoSoj"
   },
   "source": [
    "Let's calculate accuracy (accuracy of model must be > 0.95):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "epQsquZ8oSoj"
   },
   "outputs": [],
   "source": [
    "actual = list(test_set_y)\n",
    "accuracy = (y_predictions == test_set_y).mean()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0GUUxwmuoSol"
   },
   "source": [
    "Let's check the difference between real and predicted labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "tUzqLPzDoSom"
   },
   "outputs": [],
   "source": [
    "for index, feature_name in enumerate(visualization_set.feature_names):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.scatter(test_set_x[:, index], test_set_y) # real labels\n",
    "    plt.scatter(test_set_x[:, index], y_predictions) # predicted labels\n",
    "    plt.ylabel(\"Class\", size=15)\n",
    "    plt.xlabel(feature_name, size=15)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKKdyvXpoSop"
   },
   "source": [
    "## 6 - Conclusion\n",
    "As we can see, our model fits well to the data.\n",
    "\n",
    "#### What's next:\n",
    "1. Try experimenting with the `k` to see how this affects the model you have built.\n",
    "2. Compare the results you have obtained with the `sklearn.neighbors.KNeighborsClassifier` model.\n",
    "3. Try this model in the wild! Select your favorite dataset [here](https://www.kaggle.com/datasets?sortBy=hottest&group=public&page=1&pageSize=20&size=small&filetype=all&license=all&tagids=13303) and play with it."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "KNN.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
